#include <iostream>
#include <vector>
#include <algorithm>
#include <string>
#include <utility>
#include <cstring>
#include <string.h>
#include<string>
#include <unordered_set>
using namespace std;

const int INF = 1e9;
const int MOD = 1e9 + 7;

#define ll long long
#define lli long long int

/*

A necessary condition for ð‘ 
 to be good is that ð‘ 1â‰ ð‘ ð‘›
. For a string ð‘ 
 where ð‘ 1â‰ ð‘ ð‘›
, let ð‘¡1
 be a string composed of just the single character ð‘ 1
, and let ð‘¡2
 be a string composed of the ð‘›âˆ’1
 characters from ð‘ 2
 to ð‘ ð‘›
. In this way, the condition is satisfied.

Therefore, if ð‘ 1â‰ ð‘ ð‘›
, the answer is "Yes"; otherwise, the answer is "No".

Time complexity: ð‘‚(ð‘›)
 per test case

*/

//this is the best solution ,my solution you can check on codeforces, mine was a bit lengthy

void solve() {
    string s;
    int n;
    cin >> n >> s;

    if(s[0] != s[n-1]) cout<<"YES"<<endl;
    else cout<<"NO"<<endl;

}

int main()
{
  ios::sync_with_stdio(false);
  cin.tie(nullptr);

  ll t = 1;
  cin >> t;
  while (t--)
  {
    solve();
  }

  return 0;
}